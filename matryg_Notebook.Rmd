---
title: "ICY0006 - Probability Theory and Statistics - Matryg project, TalTech"
output: html_notebook
---

# Stage 1  

## Introduction
This is my project for the course ICY0006 - Probability Theory and Statistics at TalTech University.  
Among the content of my project is a matryg_Notebook.Rmd-file and from that file a html-file can be generated and read as a report.
Any questions related to the report can be sent to my mail: matryg@ttu.ee  
The link to my GitHub repo is https://github.com/matry18/matrygV3  
Enjoy the reading!  

## The work environment  
For this project I have used RStudio as my IDE. I have used version control with Git and continuously committed my work to GitHub, where the repository is public accessible.  
I have used the Notebook function in RStudio to generate the matryg_Notebook.Rmd-file from where a html-file can be generated and read as the report for this project.  
The development of the report was an ongoing process following the progression of the course and continuous implementing the topics thought in the lecture and practices.  

## The dataset  
The original dataset for this project was based on house prices and computer generated. This caused some issues since the dataset was not suitable due to the certain problem. Because of that the dataset was changed 4 weeks into the course. Doing the 8th week of the course I faced some problems with all the possible linear regressions in the dataset being heteroscedastic. This lead to another change of the dataset. Therefore this dataset is version 3 in my project.  

This dataset is about lung capacity and is public available at https://www.kaggle.com/aakashmisra/lung-capacity with an unknown license. The version of the dataset is Version 1 and was created the 28/9 2020 by the user Aakash Misra - https://www.kaggle.com/aakashmisra  
The dataset is a .csv-file and I downloaded it and unzipped it before importing it. When doing the importing of the dataset I used a dynamic file.choose() method where I chose the downloaded and unzipped file.  
```{r}
data1 <- read.csv(file.choose(), header=TRUE)
View(data1)
attach(data1)
```

To be able to manipulate and visualize the dataset the libraries and dependencies was loaded.
```{r}
##Data Manipulation
library(tidyverse)
library(psych)
library(lubridate)
library(xts)
library(tseries)
library(forecast)
library(MLmetrics)
library(MASS)
library(caTools)
#Visualisation 
library(corrplot)
library(plotly)
library(viridis)
library(ggmap)
library(knitr)
library(dygraphs)
library(ggthemes)
library(reshape)
library(reshape2)
library(ggplot2)
library(ggcorrplot)
library(ggstatsplot)
```

## Variables  
In the following I will describe the variables in the dataset.  
The dataset consists of 725 observations and has 6 variables.  

**LungCap** is short for lung capacity also know as total lung capacity (TLC). Lung capacity is the volume of air in the lungs upon the maximum effort of inspiration.  Among healthy adults, the average lung capacity is about 6 liters. Age, gender, body composition, and ethnicity are factors affecting the different ranges of lung capacity among individuals. TLC rapid increases from birth to adolescence and plateaus at around 25 years old. Males tend to have a greater TLC than females, while individuals with tall stature tend to have greater TLC than those with short stature, and individuals with a high waist-to-hip ratio generally have a lower TLC. Individuals of African descent have a lower TLC compared to individuals of European descent. Additional factors that affect an individual's lung capacity include the level of physical activity, chest wall deformities, and respiratory diseases.^[From https://www.ncbi.nlm.nih.gov/books/NBK541029/, seen 17/12-20.]  
The lung capacity is a dependent variable since it is influenced by age, gender etc. It is a continuous value as well as quantitative. It is measured on an interval scale.  

**Age** indicates the persons age in years. This variable is independent, quantitative and discrete since all the age values are presented as integer values on an interval scale.  

**Height** is the height in inches. This is an independent, continuous, quantitative variable measured on an interval scale. This variable must be transformed into a measurement of  meter. Therefore I multiply the height value with 0.0254 to get the value in meter. This value has been added to the dataset as the variable **HeightMeter** and share the same characteristics as Height.
```{r}
data1$HeightMeter <- data1[,3]*0.0254
View(data1)
```
The **Smoke** variable is independent, discrete and qualitative. It defines if the person is smoking, since it influences the lung capacity. The categorical values is "yes" if the person smokes and "no" if the person does not smoke. This is measured on a nominal scale. As an alternative the true/false-value could have been indicated with numbers, where 1 is true and 0 is false, but for now I will not manipulate the value.  

**Gender** defines the gender of the person. This variable is independent, discrete and qualitative measured on a nominal scale. If the person is male the value is "male" and if the person is female the value is "female". As an alternative the true/false-value could have been indicated with numbers, where 1 is true and 0 is false, but for now I will not manipulate the value.  


The **Caesarean** indicates how the person was born. If the person was born by caesarean the value is "yes" and if not the value is "no". This is an independent, discrete, qualitative variable measured on a nominal scale. As an alternative the true/false-value could have been indicated with numbers, where 1 is true and 0 is false, but for now I will not manipulate the value.  

### Missing data
Before going any further with the dataset I will check for any missing values by the use of the inbuilt function in R Studio.
```{r}
which(is.na(data1))
```
Since the returned value is zero that means that I don't have any missing data in my dataset.  

### Data visualization  
In the following I will visualize each variable. For Lung capacity, age and height in meters I have used histograms. Since histograms are strongly affected by the number of bins and therefore makes it difficult to determine the shape of the distribution I have added a normal curve to the histograms.  
Another way of viewing the variables could be with the use of Kernel Density plots. Therefore I have chosen to visualize the lung capacity, age and height in meters with this curve.  
**Lung capacity**
```{r}
hist(data1$LungCap, las=1, ylim= c(0,120),xlab = "Lung capacity", main= "Histogram of lung capacity")

x <- data1$LungCap
h<-hist(x, breaks=20, col="red", xlab="Lung capacity", las=1, main="Histogram with Normal Curve", ylim = c(0,120), xlim = c(0,15))
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)

plot(density(data1$LungCap), main = "Kernel Density of lung capacity", xlab = "Lung capacity", las=1)
```
**Age**
```{r}
hist(data1$Age, xlim = c(0,20), ylim=c(0,80), las=1, xlab = "Age in years", main= "Histogram of age", breaks = 20)

x <- data1$Age
h<-hist(x, breaks=20, col="red", xlab="Age in years", las=1, main="Histogram with Normal Curve", ylim = c(0,80), xlim = c(0,20))
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)

plot(density(data1$Age), main = "Kernel Density of age", xlab = "Age in years", las=1)
```

**Height in meters**
```{r}
hist(data1$HeightMeter, xlim= c(1,2.2), ylim = c(0,100), las=1, xlab = "Height in meter", main= "Histogram of height in meter", breaks = 20)

x <- data1$HeightMeter
h<-hist(x, breaks=20, col="red", xlab="Height in meter", las=1, main="Histogram with Normal Curve", ylim = c(0,100), xlim = c(1,2.2))
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)

plot(density(data1$HeightMeter), main = "Kernel Density of height in meter", xlab = "Height in meter", las=1)
```
In the following I will visualize the categorial variables with pie chart since it makes a good overview.  

**Smoke**
```{r}
smoke.count<-table(data1$Smoke)
lbls <- paste(names(smoke.count), "\n", smoke.count, sep="")
pie(smoke.count,border=T, labels = lbls,
   main="Distribution of people who smoke,\n (with sample sizes)")
```
**Gender**
```{r}
gender.count<-table(data1$Gender)
lbls <- paste(names(gender.count), "\n", gender.count, sep="")
pie(gender.count,border=T, labels = lbls,
   main="Distribution of gender,\n (with sample sizes)")
```
**Caesarean**
```{r}
caesarean.count<-table(data1$Caesarean)
lbls <- paste(names(caesarean.count), "\n", caesarean.count, sep="")
pie(caesarean.count,border=T, labels = lbls,
   main="Distribution of people born by caesarean,\n (with sample sizes)")
```
### Interpreting the visualization  
In the following I will describe what can be seen from the graphs and charts.  

The lung capacity has a nice bell shape, which indicates a normal distribution. The distribution is very close to be complete symmetrical with a single peek.  
The age variable is close of having a nice bell shape but it tends to have a small negative skewness. It has a single peek and is close to being symmetrical but not complete symmetrical.  
The height in meter has a very nice bell shape which indicates a normal distribution with a single peek and the shape of it is very close to be symmetrical.  
The distribution of people who smoke indicates that approx. 1/8 of the people in the population do smoke and 7/8 does not.  
The distribution of genders is close to be even with slightly more males than females in the population.  
The distribution of people born by ceasarean shows that nearly 1/4 of the population is born by caesarean and 3/4 is not.  

# Stage 2  
## Quantitative overview of data  

In the following we will compute the central tendency, also known as measure of central tendency or average. Basically this is the central value for a probability distribution. I will also compute the variability measures which is how "spread out" the data is. Then I will do a short analysis of the central tendencies and variability measures and compare the outcome with the visual representation of the distributions.  

### Central tendency measures  

#### Mean, trimmed mean, median and mode  

The mean is the sum of numerical values of each observation divided by the total number of observations, or put in a simpler way the sum of numbers divided by the number of numbers. The mean indicates at what point the distribution is in balance. In the following you will see the population mean for lung capacity, age and height in meters.  

**Lung capacity mean**
```{r}
lungCap.mean <- mean(data1$LungCap)
print(lungCap.mean)
```
**Age mean**
```{r}
age.mean <- mean(data1$Age)
print(age.mean)
```
Since the age variable is discrete I will have to round of the mean value to not have a decimal number.
```{r}
print(round(age.mean))
```
**Height in meters mean**
```{r}
heightMeter.mean <- mean(data1$HeightMeter)
print(heightMeter.mean)
```
With the trimmed mean I remove the lower and upper values in the distribution. In the following I will present a trimmed mean of 20 % for the same variables as above. This means that I will remove the lower 10 % and upper 10 % from the distribution and then recalculate the mean value.  

**Lung capacity trimmed mean of 20 %**
```{r}
mean(data1$LungCap, trim = 0.2)
```
**Age trimmed mean of 20 %**
```{r}
mean(data1$Age, trim = 0.2)
```
And since age is a discrete variable it will have to be rounded of.
```{r}
round(mean(data1$Age, trim = 0.2))
```
**Height in meter trimmed mean of 20 %**
```{r}
mean(data1$HeightMeter, trim = 0.2)
```
The median is the 50th percentile of the distribution which is the same as the value in the exact middle of the distribution. If the distribution is a even number, then I will take the average of the middle two values. The median can be found with the summary-function i R.
```{r}
summary(data1)
```
This shows the median for **lung capacity** is 8.0, for **age** it is 13.0 and for **height in meter** it is 1.661.  

The mode is the most frequent value in the distribution for a given variable. To compute the mode I use a function.  
```{r}
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
```
**Mode lung capacity**
```{r}
lungCap.mode <- getmode(data1$LungCap)
print(lungCap.mode)
```
**Mode age**
```{r}
age.mode <- getmode(data1$Age)
print(age.mode)
```
**Mode height in meter**
```{r}
heightMeter.mode <- getmode(data1$HeightMeter)
print(heightMeter.mode)
```
### Variability measures  

#### Range & interquartile range  

The range of an observation variable is the difference of its largest and smallest data values. It is a measure of how far apart the entire data spreads in value.  

**Lung capacity range**
```{r}
print(range(data1$LungCap))
```
**Age range**
```{r}
print(range(data1$Age))
```
**Height in meter range**
```{r}
print(range(data1$HeightMeter))
```
The interquartile range (IQR) of an observation variable is the difference of its upper and lower quartiles. It is a measure of how far apart the middle portion of data spreads in value. In other words it is the range of the middle 50 % of the scores in a distribution.  

**Lung capacity IQR**
```{r}
IQR(data1$LungCap)
```
**Age IQR**
```{r}
IQR(data1$Age)
```
**Height in meter IQR**
```{r}
IQR(data1$HeightMeter)
```
#### Variance & Standard Deviation  

The variance is a numerical measure of how the data values is dispersed around the mean. Please notice that there is a difference in the variance depending on if it is from a population or sample! In the following I am looking at the variance on a population for lung capacity, age and height in meter.  

**Lung capacity variance**
```{r}
print(var(data1$LungCap))
```
**Age variance**
```{r}
print(var(data1$Age))
```
The variance produces a measures of how far a set of numbers is spread out from their average value. Since age is a discrete value it has to be rounded off.
```{r}
print(round(var(data1$Age)))
```
**Height in meter variance**
```{r}
print(var(data1$HeightMeter))
```
The standard deviation (SD) of an observation variable is the square root of its variance. This is a useful measure of variability when the distribution is normal (or close to) because the proportion of the distribution within a given number of standard deviations from the mean can be calculated. Put in a more simple way, the SD can be used to measure the spread of the data in relation to the mean.  

**Lung capacity SD**
```{r}
print(sd(data1$LungCap))
```
**Age SD**
```{r}
print(sd(data1$Age))
```
Again the value has to be an integer so it is rounded off.
```{r}
print(round(sd(data1$Age)))
```
**Height in meter SD**
```{r}
print(sd(data1$HeightMeter))
```
### Analysis  

#### Lung capacity  
The mean and trimmed mean is very close to each other which indicates that no majority of data points is located in the outer 10 % of the lower or upper end of the distribution. The mean and the median is also very close to each other which indicates that the balance of the distribution is close to the center of the distribution. This would imply that the distribution is very close to a normal distribution which can be confirmed by the visual representation. The mode is 8.35 which corresponds very well with the histogram and curve since that is the peek. From the visual representation is can be difficult to read the exact value so the exact mode value is very helpful. The range values defines that start and end value for the variable, so the worst lung capacity is 0.507 and the best is 14.675. The IQR of 3.65 indicates that the middle 50 % of the data is not that wide spread in the distribution. The SD value (2.662008) is quite small which tells me that the spread of the data points from the mean is quite narrow. The variability measures corresponds very well with the graphical representation of the distribution.  

#### Age  
The mean and trimmed mean is actually really close to each other but when the value is rounded off the difference increases but the two values (12 and 13) is still close to each other. From this I can deduce that there is not many data points in the outer 10 % of the lower and upper part of the distribution. The mean and median is also very close to each other so the balance of the distribution is in the center of the distribution. The mode value is equal to the trimmed mean and median which indicates a normal distribution which can be confirmed by the visual representation of the histogram and density curve. Since the mean value is smaller than the median value a small negative skew can be seen. The central tendency values and the visual representation corresponds very well with each other. The youngest person in the population is 3 years old and the oldest is 19 years old. The IQR value of 6 indicates that the central 50 % of the data is spread out among those 6 years. The SD value of 4 indicate how far from the mean value that the data is spread out. The value indicates that there is some spread among the observations for this variable but nothing of big concern. The variability measures correspons very well with the visual representation of the distribution.  

#### Height in meter  
The mean and trimmed mean is almost identical so no crucial data points is located in the outer 10 % of the scale for this variable. The same goes for the mode value which is identical with the medial value. This indicates a symmetric distribution and when looking at the visual representation of the distribution this corresponds very well with the values. The shortest person in the observations is 1.15062 meter and the tallest person is 2.07772 meter. The IQR value of 0.26416 indicates that the central 50 % of the data is not that wide spread out. The SD value (0.1829345) is relatively small and indicates that the data for this variable is not that wide spread out. The variability measures corresponds very well with the graphical representation of the distribution.  

I have chosen to leave out some of the variables when it did not add any value to the project to analyze variables such as true-false variables and other categorical variables.  

I general the graphical representation gives the same impression as the values of central tendency measures and variability measures. However it can be difficult to read the exact values from the graphical representation and the central tendency measures and variability measures helps to understand the exact values.  
When the values are rounded some details becomes hidden from the central tendency measures. The data representation can either be in numeric form or visual form depending on how you want to present the data and with what purpose. Usually it is easier to get an overview from the visual representation but the details is easier seen in the numerical representation of the data.  

# Stage 3

## Linear relationships between variables  

In the following I will select the suitable variables for linear relationships and remove outliers. Then I will compute a correlation matrix and visualize it with a heat map and explain what it shows.  

As for variables I have selected lung capacity, age and height in meters since they are not categorical.  

### Removing outliers  

Then I'll remove the outliers in those variables. Often an outlier is an anomaly in the dataset that occurs because of the measurement errors, but also because the experiment being observed experiences momentary but drastic turbulence. The outliers can have a huge impact on the result of a linear regression model. The statistical parameters e.g. mean, standard deviation (SD) and correlation are impacted by outliers. To locate the outliers one can use the IQR as it does not depend on the mean and SD.  
The IQR is the central 50 % which is the same as the area above the 25th percentile of a distribution and under the 75th percentile of an distribution. A point is defined as an outlier if it is below the 25th or above the 75th percentile by a factor of 1,5 times the IQR. The outliers can be visualized in a boxplot, since the boxplot shows the median and the 1st and 3rd quartiles.  
The below boxplot is just an example on how to visualize the outliers.  
```{r}
boxplot(data1$LungCap, las=1, main= "Boxplot for lung capacity")
```
From the above boxplot one outlier can be seen. but it can be difficult to read the exact value of the outliers in a boxplot. Therefore a statistical method for finding outliers is needed. By using the quantile() function I can find find the 25th and 75th percentile, and by using the IQR() function I can see the difference between the 75th and 25th percentiles.
```{r}
# Lung capacity
Q_lung <- quantile(data1$LungCap, probs = c(0.25, 0.75), na.rm = FALSE)
iqr_lung <- IQR(data1$LungCap)
# Age
Q_age <- quantile(data1$Age, probs = c(0.25, 0.75), na.rm = FALSE)
iqr_age <- IQR(data1$Age)
# Height in meter
Q_heightMeter <- quantile(data1$HeightMeter, probs = c(0.25, 0.75), na.rm = FALSE)
iqr_heightMeter <- IQR(data1$HeightMeter)
```
From the above values I can find the cut-off ranges beyond which all data points are outliers.  
```{r}
# Lung capacity
up_lung <-  Q_lung[2]+1.5*iqr_lung # Upper Range  
low_lung<- Q_lung[1]-1.5*iqr_lung # Lower Range

# Age
up_age <-  Q_age[2]+1.5*iqr_age # Upper Range  
low_age<- Q_age[1]-1.5*iqr_age # Lower Range

# Height in meter
up_heightMeter <-  Q_heightMeter[2]+1.5*iqr_heightMeter # Upper Range  
low_heightMeter<- Q_heightMeter[1]-1.5*iqr_heightMeter # Lower Range
```
By using the subset() function I can extract the data between the lower and upper, leaving out the outliers.

```{r}
data2=subset(data1, LungCap > low_lung & LungCap < up_lung & Age > low_age & Age < up_age & HeightMeter > low_heightMeter & HeightMeter < up_heightMeter)
boxplot(data2$LungCap, las=1, main= "Boxplot for lung capacity")
```
When looking at the updated dataset (data2) it has 1 less observation than the old dataset (data1) which means that I only had 1 outlier.
```{r}
view(data2)
```
### Correlation matrix and visualization  
In the following I will compute a correlation matrix and visualize it with a heat map.  

A heat map relates the numeric value from -1 to 1 into a color code where red represents a value of 1 and blue represents a value of -1. 0 indicates a non-correlation. To make the heat map a bit easier to read I have rounded the numerical value to two decimal numbers.  
```{r}
numVar <- data2 %>% select(LungCap, Age, HeightMeter)
cor(numVar)
corMatrix <- round(cor(numVar),2)
p.mat<-cor_pmat(numVar)
ggcorrplot(corMatrix,outline.col = "white",  hc.order = TRUE,type = "full",lab = TRUE,p.mat = p.mat)
```
From the correlation matrix and the heat map there seems to be a very strong correlation between lung capacity and height in meter since the Pearson's correlation coefficient is 0.91. There is a strong correlation between age and lung capacity (0.82 Pearson's correlation coefficient) as well as between age and height in meter (0.83 Pearson's correlation coefficient). There is a perfect correlation between a variable and itself but that should be excluded and not be looked into.  
The lung capacity must be the dependent variable, depending on both age and height in meter.  

## Scatterplot - dependent variable vs. independent variable  
From the above correlation matrix I know that lung capacity is the dependent variable, where age and height in meter is the independent variables. In the following I will create scatterplots for respectively lung capacity vs. age, and lung capacity vs. height in meter.  

**Lung capacity vs. age**  
```{r}
plot(data2$Age, data2$LungCap, main ="Scatterplot: Lung capacity vs. age", ylab = "Lung capacity", xlab = "Age in years", las=1, xlim=c(0,20), ylim=c(0,15))
```
From the scatterplot I can see a strong relationship between age and lung capacity. The higher the age value the higher the lung capacity value. The two variables has a positive association. I can also observe a linear relationship since the points clusters along a straight (wide) line. The scatterplot shows homoscedasticity since all the random variables have the same finite variance. From the scatterplot it is visible that the age variable is discrete since all the points forms a vertical "line".  

**Lung capacity vs. height in meter**  
```{r}
plot(data2$HeightMeter, data2$LungCap, main ="Scatterplot: Lung capacity vs. height in meter", ylab = "Lung capacity", xlab = "Height in meter", las=1, xlim=c(1.1,2.1), ylim=c(0,15))
```
The scatterplots shows a strong relationship between lung capacity and height in meter. It is easy to see that when the value for height in meter increases the lung capacity increases as well. I can see a positive linear relationship between the two variables. The scatterplot is in a homoscedastic form. I can see that both variables are continuous since the points in the plot is not in a vertical or horizontal "line".  

## Linear regression model

In the following I will look into a linear regression model and visualize it with a scatter plot with a line.  
I have chosen lung capacity vs. height in meter, since it has the highest correlation coefficient value.
```{r}
cor(data2$LungCap,data2$HeightMeter)
mod <- lm(data2$LungCap ~ data2$HeightMeter)
summary(mod)
mod$coefficients
plot(data2$HeightMeter, data2$LungCap, main ="Scatterplot: Lung capacity vs. height in meter", ylab = "Lung capacity", xlab = "Height in meter", las=1, xlim=c(1.1,2.1), ylim=c(0,15))
abline(mod, col=2, lwd=3)
plot(mod$residuals, col="blue", lwd=2, ylab="Residuals", las=1, main = "Scatterplot for residuals")
abline(h=0)
```
In the summary the residuals (errors) are shown, e.g. the residual value for median is -0.0060. The estimate for the intercept is -13.9263 and it's standard error is  0.3669. The regression coefficient is the average change in the dependent variable (lung capacity) for a 1-unit change in the independent variable (height in meter). It is the slope of the regression line. For height in meter the estimate is 13.2335 and the standard error is 0.2213. The residual standard error is 1.087 which is a measure of a variation of observations around the regression line. This is the same as the square root of the mean squared error. The residual standard error tells how far observed lung capacity are from the predicted or fitted lung capacity. The multiple R-squared values (0.832) means that approx. 83 % of variation of lung capacity can be explained by this model.  
I can see that the height in meter is the cause of the lung capacity. Both of the variables is continuous and have a strong positive linear relationship. The red line (the least squared regression line) is the prediction of the lung capacity based on the height in meter. All the points are the actual data values. The distance from a point to the line is the error called residual, since it is the difference between the actual data point and the predicted value. The line passes through the mean of both variables (lung capacity and height in meter).  
The scatterplot for the residuals shows a random pattern.  

## Regression with multiple variables  
In the following I will look into regression with multiple variables. I will use lung capacity as the dependent variable and age and height in meter as the independent variables to fit my linear regression model.
```{r}
model1 <- lm(data2$LungCap ~ data2$Age + data2$HeightMeter)
summary(model1)
cor(data2$Age, data2$HeightMeter, method = "pearson")
confint(model1, conf.level=0.95)
plot(model1)
```
From the summary I can see that the R-squared is 0.8425 which means that approx. 84 % of variation in lung capacity can be explained by this model using age and height in meter. The residual standard error is 1.053 on 721 degrees of freedom. This gives me an idea of how far observed lung capacity (Y values) are form the predicted or fitted lung capacity (the Y-hats). The Intercept of -11.72674 is the estimated mean Y (lung capacity) value when all X-values (age and height in meter) are zero. In other words it is the estimated mean lung capacity for a person with age and height in meter of zero. The value for age estimated is 0.12409. This is the effect of Age on lung capacity adjusting or controlling for height in meter. In other words an increase of 1 year in age is associated with an increase of 0.12409 in lung capacity adjusting or controlling for height in meter. The slope for height in meter is 10.96872. This is the estimated effect of height in meter on lung capacity adjusting for age.  

The Pearson's correlation between age and height in meter is 0.8348995 so the two variables are very highly correlated. The collinearity between age and height in meter means that I should not directly interpret the slope (e.g. age), as the effect of age on lung capacity adjusting for height in meter. The high correlation between age and height in meter suggests that these two effects are somewhat bounded together.  

The estimated slope for age is 0.12409 or 95 % confident that the true slope is between 0.08910293 and 0.1590719. The estimated slope for height in meter is 10.96872 or 95 % confident that the true slope is between 10.20394027 and 11.7335008.  

To check the regression diagnostics for this model with two independent variables I'll look at the plot for residuals vs. fitted. The relationship between lung capacity and age and height in meter is approx. linear. The variation looks constant. The lung capacity given age and height in meter is approx. normal which can been seen on the Normal Q-Q plot.  

If I wanted to fit a model with all the possible X-variables that would be age, height in meter, smoke, gender and caesarean, this could be done so.
```{r}
model2 <- lm(data2$LungCap ~ data2$Age + data2$HeightMeter + data2$Smoke + data2$Gender + data2$Caesarean)
summary(model2)
plot(model2)
```
The two models is close to each other but the multiple R-squared is higher for the model with all the X-variables. Also the residual standard error value is lower for the model with all the X-values. This makes good sense since a model provided with more data points should be able to produce a more correct estimate.  

# Stage 5 - Training and testing regression model  

In the following I will first split my dataset into a training and testing model. I will train my regression model on the training set and then I will test my model on the training set and evaluate my model for how well it is to predict unknown (future) values.  

## Splitting the dataset  
In the following I will split my dataset into a training and testing set. The training set is used for training the model for predicting values and the testing set is used to test how well the model actually predicts the actual values in the testing set. It is worth to understand that the predicted value in the testing set has not been shown to the model before.  
I am splitting my dataset randomly into the training set which will consist of 80 % of the original dataset and the last 20 % will be the testing set. It's important to never ever train on the testing data set since it will skew the results and introduce bias into the results.  
```{r}
split = sample.split(data2$LungCap, SplitRatio = 0.8)
training_set = subset(data2, split == TRUE)
test_set = subset(data2, split == FALSE)
```
The training set contains 614 observations and the test set contains 110 observations. Due to rounding errors the training set is 0.8480663 % of the whole dataset and the testing set is 0.1519337 % of the whole dataset.  

## Training the model  
In the following I will train different regression models on the training set. I will at first train a model with one parameter and thereafter a model with multiple parameters.  
```{r}
cor(training_set$LungCap,training_set$HeightMeter)
train_mod <- lm(training_set$LungCap ~ training_set$HeightMeter)
summary(train_mod)
plot(training_set$HeightMeter, training_set$LungCap, main ="Scatterplot: Lung capacity vs. height in meter - training set", ylab = "Lung capacity", xlab = "Height in meter", las=1, xlim=c(1.1,2.1), ylim=c(0,15))
abline(train_mod, col=2, lwd=3)
plot(train_mod$residuals, col="blue", lwd=2, ylab="Residuals", las=1, main = "Scatterplot for residuals - training set")
abline(h=0)
```
When I look at the correlation coefficient between lung capacity and height in meter there seems to be a very strong correlation. The scatterplot indicates a strong linear relationship between the lung capacity and the height in meter. The scatterplot for the residuals also show how the residuals are randomly distributed. The residual standard error is 1.108 which in a moment will be compared with an other linear regression model.  

Now I will train a regression model with multiple variables as both height in meter and age.
```{r}
train_model1 <- lm(training_set$LungCap ~ training_set$Age + training_set$HeightMeter)
summary(train_model1)
plot(train_model1)
```
From the above linear model based on multiple variables the main point for now is to look at the residual standard error, which is 1.08. This will be discussed in a moment after having trained the last linear model with multiple variables which will be age, height in meter, smoke, gender and caesarean.
```{r}
train_model2 <- lm(training_set$LungCap ~ training_set$Age + training_set$HeightMeter + training_set$Smoke + training_set$Gender + training_set$Caesarean)
summary(train_model2)
plot(train_model2)
```
For the last model with multiple variables the residual standard error is 1.04. Compared with the other two models based on the training set, this model has the lowest error. Then follows the other model with multiple variables (train_model1) and at last comes the model with a single parameter.  

## Testing the model  
In the following I will test my models and evaluate how well they perform. To assess my models performance on unseen data that's why I train on the training data set and then I use a subset of that data which is the testing data set. If the model is not tested and is made such that it performs good only on that whole training data set, then the parameters will be tuned in a way that they are only good enough to predict the value for the data which was in the training data set, and that is not generically applicable to any other data sets that I want to carry the model over to and that is called overfitting. I want to avoid overfitting and underfitting my models.  



# Lottery - Stage 4

## Viking Lotto  
I have chosen one of the Danish lottery systems, known as "Viking Lotto", which can be found here:
https://danskespil.dk/vikinglotto/vindertal  

The lottery ticket has a game board with 36 elements which are the numbers from 1-36. The player should choose 7 numbers on the game board - this is known as a row.  

Once a week the lottery numbers are drawn. There is drawn 7 winning numbers and 2 additional numbers.  
The criteria for a success is:  
- 6 winning numbers plus 1 of the additional numbers.  
- 6 winning numbers.  
- 5 winning numbers plus 1 of the additional numbers.  
- 5 winning numbers.  
- 4 winning numbers plus 1 of the additional numbers.  
- 4 winning numbers.  
- 3 winning numbers.  

In the lottery the sequence of the 7 winning numbers is selected among the fist 36 positive integers and the sequence of the winning numbers is not relevant. To calculate the possible sequences of winning numbers I use the formula:  
(n,k) = n(n-1)...(n-k+1) / k(k-1)...1  
The same formula can be written with factorials:  
n! / (k!*(n-k)!), when k <= n, and which is zero when k>n.
```{r}
kombin <- function(n,k)
{
  factorial(n) / (factorial(k)*factorial(n-k))
}
```
The number of possible rows is (36,7) = 8347680.
```{r}
kombin(36,7)
```
I will start out with the simplest of the cases where I only focus on the winning numbers.  
Let x denote the number of correct winning numbers.  
The number of rows with x number of correct winning numbers is (7,x)*(29,7-x), which is the number of ways the correct x numbers can be among the correct 7 winning numbers multiplied with the number of ways the remaining 7-x numbers in the row can be selected from the 29 numbers which are not the correct winning numbers.  
P(x) = ((7,x)*(29,7-x)) / (36,7)  
**x = 6  **
```{r}
(kombin(7,6)*kombin(29,7-6)) / kombin(36,7)
```
**x = 5**
```{r}
(kombin(7,5)*kombin(29,7-5)) / kombin(36,7)
```
**x = 4**
```{r}
(kombin(7,4)*kombin(29,7-4)) / kombin(36,7)
```
**x = 3**
```{r}
(kombin(7,3)*kombin(29,7-3)) / kombin(36,7)
```
The above results only focus on the cases where the winning numbers are drawn and not the additional numbers. The additional numbers is two numbers. Let y denote the number of correct additional numbers. I can either have 0, 1 or 2 correct additional numbers.  
I will use the following formula:  
P(x correct winning numbers and y correct additional numbers) = ( (7,x)* (2,y)* (27,7-(x+y)) ) / (36,7)  

First I'll find the number of combinations for x to be among the correct 7 winning numbers, they are multiplied with the number of combinations for y to be among the correct 2 additional numbers, multiplied with the number of ways where the remaining 7-(x and y) numbers of the row is selected among the 27 numbers which is not correct.

If I have **6 winning numbers and 1 additional number** the formula looks like this:  
P(6,1) = ( (7,6)* (2,1)* (27,7-(6+1)) ) / (36,7)
```{r}
(kombin(7,6)*kombin(2,1)*kombin(27,7-(6+1))) / kombin(36,7)
```
**5 winning numbers and 1 additional number**
```{r}
(kombin(7,5)*kombin(2,1)*kombin(27,7-(5+1))) / kombin(36,7)
```
**4 winning numbers and 1 additional number**
```{r}
(kombin(7,4)*kombin(2,1)*kombin(27,7-(4+1))) / kombin(36,7)
```
It would make sense that the lower the probability the higher the price. The order of the price is related to the number of correct winning numbers and additional numbers: 6 winning numbers + 1 additional number > 6 winning numbers > 5 winning numbers + 1 additional number > 5 winning numbers  > 4 winning numbers + 1 additional number > 4 winning numbers > 3 winning numbers.  
Let's compare the probability the highest price should have the lowest probability
```{r}
"(kombin(7,6)*kombin(2,1)*kombin(27,7-(6+1))) / kombin(36,7)"<"(kombin(7,6)*kombin(29,7-6)) / kombin(36,7)<(kombin(7,5)*kombin(2,1)*kombin(27,7-(5+1))) / kombin(36,7)<(kombin(7,5)*kombin(29,7-5)) / kombin(36,7)<(kombin(7,4)*kombin(2,1)*kombin(27,7-(4+1))) / kombin(36,7)<(kombin(7,4)*kombin(29,7-4)) / kombin(36,7)<(kombin(7,3)*kombin(29,7-3)) / kombin(36,7)"
```
```{r}
(kombin(7,6)*kombin(2,1)*kombin(27,7-(6+1))) / kombin(36,7)
(kombin(7,6)*kombin(29,7-6)) / kombin(36,7)
(kombin(7,5)*kombin(2,1)*kombin(27,7-(5+1))) / kombin(36,7) 
(kombin(7,5)*kombin(29,7-5)) / kombin(36,7)
(kombin(7,4)*kombin(2,1)*kombin(27,7-(4+1))) / kombin(36,7)
(kombin(7,4)*kombin(29,7-4)) / kombin(36,7)
(kombin(7,3)*kombin(29,7-3)) / kombin(36,7)
```
I have both evaluated that the highest price is associated with the lowest probability and when the probability increases the price is decreasing. It can be observed that there is a lower probability of getting x number of winning numbers and the additional numbers, than just the winning numbers. This makes quite good sense the probability of the correct additional numbers is multiplied in the equation. If we look at the result numbers we have to remember that it is a value between 0-1, where 0 indicates no probability of the outcome (it is impossible) and 1 indicates it will happen for sure. There is a very small chance to win in the lottery, even just to have 3 correct winning numbers.