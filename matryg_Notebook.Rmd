---
title: "ICY0006 - Probability Theory and Statistics - Matryg project, TalTech"
output: html_notebook
---

# Stage 1  

## Introduction
This is my project for the course ICY0006 - Probability Theory and Statistics at TalTech University.  
Among the content of my project is a matryg_Notebook.Rmd-file and from that file a html-file can be generated and read as a report.
Any questions related to the report can be sent to my mail: matryg@ttu.ee  
The link to my GitHub repo is https://github.com/matry18/matrygV3  
Enjoy the reading!  

## The work environment  
For this project I have used RStudio as my IDE. I have used version control with Git and continuously committed my work to GitHub, where the repository is public accessible.  
I have used the Notebook function in RStudio to generate the matryg_Notebook.Rmd-file from where a html-file can be generated and read as the report for this project.  
The development of the report was an ongoing process following the progression of the course and continuous implementing the topics thought in the lecture and practices.  

## The dataset  
The original dataset for this project was based on house prices and computer generated. This caused some issues since the dataset was not suitable due to the certain problem. Because of that the dataset was changed 4 weeks into the course. Doing the 8th week of the course I faced some problems with all the possible linear regressions in the dataset being heteroscedastic. This lead to another change of the dataset. Therefore this dataset is version 3 in my project.  

This dataset is about lung capacity and is public available at https://www.kaggle.com/aakashmisra/lung-capacity with an unknown license. The version of the dataset is Version 1 and was created the 28/9 2020 by the user Aakash Misra - https://www.kaggle.com/aakashmisra  
The dataset is a .csv-file and I downloaded it and unzipped it before importing it. When doing the importing of the dataset I used a dynamic file.choose() method where I chose the downloaded and unzipped file.  
```{r}
data1 <- read.csv(file.choose(), header=TRUE)
View(data1)
attach(data1)
```

To be able to manipulate and visualize the dataset the libraries and dependencies was loaded.
```{r}
##Data Manipulation
library(tidyverse)
library(psych)
library(lubridate)
library(xts)
library(tseries)
library(forecast)
library(MLmetrics)
library(MASS)
#Visualisation 
library(corrplot)
library(plotly)
library(viridis)
library(ggmap)
library(knitr)
library(dygraphs)
library(ggthemes)
library(reshape)
library(reshape2)
library(ggplot2)
library(ggcorrplot)
library(ggstatsplot)
```

## Variables  
In the following I will describe the variables in the dataset.  
The dataset consists of 725 observations and has 6 variables.  

**LungCap** is short for lung capacity also know as total lung capacity (TLC). Lung capacity is the volume of air in the lungs upon the maximum effort of inspiration.  Among healthy adults, the average lung capacity is about 6 liters. Age, gender, body composition, and ethnicity are factors affecting the different ranges of lung capacity among individuals. TLC rapid increases from birth to adolescence and plateaus at around 25 years old. Males tend to have a greater TLC than females, while individuals with tall stature tend to have greater TLC than those with short stature, and individuals with a high waist-to-hip ratio generally have a lower TLC. Individuals of African descent have a lower TLC compared to individuals of European descent. Additional factors that affect an individual's lung capacity include the level of physical activity, chest wall deformities, and respiratory diseases.^[From https://www.ncbi.nlm.nih.gov/books/NBK541029/, seen 17/12-20.]  
The lung capacity is a dependent variable since it is influenced by age, gender etc. It is a continuous value as well as quantitative. It is measured on an interval scale.  

**Age** indicates the persons age in years. This variable is independent, quantitative and discrete since all the age values are presented as integer values on an interval scale.  

**Height** is the height in inches. This is an independent, continuous, quantitative variable measured on an interval scale. This variable must be transformed into a measurement of  meter. Therefore I multiply the height value with 0.0254 to get the value in meter. This value has been added to the dataset as the variable **HeightMeter** and share the same characteristics as Height.
```{r}
data1$HeightMeter <- data1[,3]*0.0254
View(data1)
```
The **Smoke** variable is independent, discrete and qualitative. It defines if the person is smoking, since it influences the lung capacity. The categorical values is "yes" if the person smokes and "no" if the person does not smoke. This is measured on a nominal scale. As an alternative the true/false-value could have been indicated with numbers, where 1 is true and 0 is false, but for now I will not manipulate the value.  

**Gender** defines the gender of the person. This variable is independent, discrete and qualitative measured on a nominal scale. If the person is male the value is "male" and if the person is female the value is "female". As an alternative the true/false-value could have been indicated with numbers, where 1 is true and 0 is false, but for now I will not manipulate the value.  


The **Caesarean** indicates how the person was born. If the person was born by caesarean the value is "yes" and if not the value is "no". This is an independent, discrete, qualitative variable measured on a nominal scale. As an alternative the true/false-value could have been indicated with numbers, where 1 is true and 0 is false, but for now I will not manipulate the value.  

### Missing data
Before going any further with the dataset I will check for any missing values by the use of the inbuilt function in R Studio.
```{r}
which(is.na(data1))
```
Since the returned value is zero that means that I don't have any missing data in my dataset.  

### Data visualization  
In the following I will visualize each variable. For Lung capacity, age and height in meters I have used histograms. Since histograms are strongly affected by the number of bins and therefore makes it difficult to determine the shape of the distribution I have added a normal curve to the histograms.  
Another way of viewing the variables could be with the use of Kernel Density plots. Therefore I have chosen to visualize the lung capacity, age and height in meters with this curve.  
**Lung capacity**
```{r}
hist(data1$LungCap, las=1, ylim= c(0,120),xlab = "Lung capacity", main= "Histogram of lung capacity")

x <- data1$LungCap
h<-hist(x, breaks=20, col="red", xlab="Lung capacity", las=1, main="Histogram with Normal Curve", ylim = c(0,120), xlim = c(0,15))
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)

plot(density(data1$LungCap), main = "Kernel Density of lung capacity", xlab = "Lung capacity", las=1)
```
**Age**
```{r}
hist(data1$Age, xlim = c(0,20), ylim=c(0,80), las=1, xlab = "Age in years", main= "Histogram of age", breaks = 20)

x <- data1$Age
h<-hist(x, breaks=20, col="red", xlab="Age in years", las=1, main="Histogram with Normal Curve", ylim = c(0,80), xlim = c(0,20))
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)

plot(density(data1$Age), main = "Kernel Density of age", xlab = "Age in years", las=1)
```

**Height in meters**
```{r}
hist(data1$HeightMeter, xlim= c(1,2.2), ylim = c(0,100), las=1, xlab = "Height in meter", main= "Histogram of height in meter", breaks = 20)

x <- data1$HeightMeter
h<-hist(x, breaks=20, col="red", xlab="Height in meter", las=1, main="Histogram with Normal Curve", ylim = c(0,100), xlim = c(1,2.2))
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)

plot(density(data1$HeightMeter), main = "Kernel Density of height in meter", xlab = "Height in meter", las=1)
```
In the following I will visualize the categorial variables with pie chart since it makes a good overview.  

**Smoke**
```{r}
smoke.count<-table(data1$Smoke)
lbls <- paste(names(smoke.count), "\n", smoke.count, sep="")
pie(smoke.count,border=T, labels = lbls,
   main="Distribution of people who smoke,\n (with sample sizes)")
```
**Gender**
```{r}
gender.count<-table(data1$Gender)
lbls <- paste(names(gender.count), "\n", gender.count, sep="")
pie(gender.count,border=T, labels = lbls,
   main="Distribution of gender,\n (with sample sizes)")
```
**Caesarean**
```{r}
caesarean.count<-table(data1$Caesarean)
lbls <- paste(names(caesarean.count), "\n", caesarean.count, sep="")
pie(caesarean.count,border=T, labels = lbls,
   main="Distribution of people born by caesarean,\n (with sample sizes)")
```
### Interpreting the visualization  
In the following I will describe what can be seen from the graphs and charts.  

The lung capacity has a nice bell shape, which indicates a normal distribution. The distribution is very close to be complete symmetrical with a single peek.  
The age variable is close of having a nice bell shape but it tends to have a small negative skewness. It has a single peek and is close to being symmetrical but not complete symmetrical.  
The height in meter has a very nice bell shape which indicates a normal distribution with a single peek and the shape of it is very close to be symmetrical.  
The distribution of people who smoke indicates that approx. 1/8 of the people in the population do smoke and 7/8 does not.  
The distribution of genders is close to be even with slightly more males than females in the population.  
The distribution of people born by ceasarean shows that nearly 1/4 of the population is born by caesarean and 3/4 is not.  

# Stage 2  
## Quantitative overview of data  

In the following we will compute the central tendency, also known as measure of central tendency or average. Basically this is the central value for a probability distribution. I will also compute the variability measures which is how "spread out" the data is. Then I will do a short analysis of the central tendencies and variability measures and compare the outcome with the visual representation of the distributions.  

### Central tendency measures  

#### Mean, trimmed mean, median and mode  

The mean is the sum of numerical values of each observation divided by the total number of observations, or put in a simpler way the sum of numbers divided by the number of numbers. The mean indicates at what point the distribution is in balance. In the following you will see the population mean for lung capacity, age and height in meters.  

**Lung capacity mean**
```{r}
lungCap.mean <- mean(data1$LungCap)
print(lungCap.mean)
```
**Age mean**
```{r}
age.mean <- mean(data1$Age)
print(age.mean)
```
Since the age variable is discrete I will have to round of the mean value to not have a decimal number.
```{r}
print(round(age.mean))
```
**Height in meters mean**
```{r}
heightMeter.mean <- mean(data1$HeightMeter)
print(heightMeter.mean)
```
With the trimmed mean I remove the lower and upper values in the distribution. In the following I will present a trimmed mean of 20 % for the same variables as above. This means that I will remove the lower 10 % and upper 10 % from the distribution and then recalculate the mean value.  

**Lung capacity trimmed mean of 20 %**
```{r}
mean(data1$LungCap, trim = 0.2)
```
**Age trimmed mean of 20 %**
```{r}
mean(data1$Age, trim = 0.2)
```
And since age is a discrete variable it will have to be rounded of.
```{r}
round(mean(data1$Age, trim = 0.2))
```
**Height in meter trimmed mean of 20 %**
```{r}
mean(data1$HeightMeter, trim = 0.2)
```
The median is the 50th percentile of the distribution which is the same as the value in the exact middle of the distribution. If the distribution is a even number, then I will take the average of the middle two values. The median can be found with the summary-function i R.
```{r}
summary(data1)
```
This shows the median for **lung capacity** is 8.0, for **age** it is 13.0 and for **height in meter** it is 1.661.  

The mode is the most frequent value in the distribution for a given variable. To compute the mode I use a function.  
```{r}
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
```
**Mode lung capacity**
```{r}
lungCap.mode <- getmode(data1$LungCap)
print(lungCap.mode)
```
**Mode age**
```{r}
age.mode <- getmode(data1$Age)
print(age.mode)
```
**Mode height in meter**
```{r}
heightMeter.mode <- getmode(data1$HeightMeter)
print(heightMeter.mode)
```
### Variability measures  

#### Range & interquartile range  

The range of an observation variable is the difference of its largest and smallest data values. It is a measure of how far apart the entire data spreads in value.  

**Lung capacity range**
```{r}
print(range(data1$LungCap))
```
**Age range**
```{r}
print(range(data1$Age))
```
**Height in meter range**
```{r}
print(range(data1$HeightMeter))
```
The interquartile range (IQR) of an observation variable is the difference of its upper and lower quartiles. It is a measure of how far apart the middle portion of data spreads in value. In other words it is the range of the middle 50 % of the scores in a distribution.  

**Lung capacity IQR**
```{r}
IQR(data1$LungCap)
```
**Age IQR**
```{r}
IQR(data1$Age)
```
**Height in meter IQR**
```{r}
IQR(data1$HeightMeter)
```
#### Variance & Standard Deviation  

The variance is a numerical measure of how the data values is dispersed around the mean. Please notice that there is a difference in the variance depending on if it is from a population or sample! In the following I am looking at the variance on a population for lung capacity, age and height in meter.  

**Lung capacity variance**
```{r}
print(var(data1$LungCap))
```
**Age variance**
```{r}
print(var(data1$Age))
```
The variance produces a measures of how far a set of numbers is spread out from their average value. Since age is a discrete value it has to be rounded off.
```{r}
print(round(var(data1$Age)))
```
**Height in meter variance**
```{r}
print(var(data1$HeightMeter))
```
The standard deviation (SD) of an observation variable is the square root of its variance. This is a useful measure of variability when the distribution is normal (or close to) because the proportion of the distribution within a given number of standard deviations from the mean can be calculated. Put in a more simple way, the SD can be used to measure the spread of the data in relation to the mean.  

**Lung capacity SD**
```{r}
print(sd(data1$LungCap))
```
**Age SD**
```{r}
print(sd(data1$Age))
```
Again the value has to be an integer so it is rounded off.
```{r}
print(round(sd(data1$Age)))
```
**Height in meter SD**
```{r}
print(sd(data1$HeightMeter))
```
### Analysis  

#### Lung capacity  
The mean and trimmed mean is very close to each other which indicates that no majority of data points is located in the outer 10 % of the lower or upper end of the distribution. The mean and the median is also very close to each other which indicates that the balance of the distribution is close to the center of the distribution. This would imply that the distribution is very close to a normal distribution which can be confirmed by the visual representation. The mode is 8.35 which corresponds very well with the histogram and curve since that is the peek. From the visual representation is can be difficult to read the exact value so the exact mode value is very helpful. The range values defines that start and end value for the variable, so the worst lung capacity is 0.507 and the best is 14.675. The IQR of 3.65 indicates that the middle 50 % of the data is not that wide spread in the distribution. The SD value (2.662008) is quite small which tells me that the spread of the data points from the mean is quite narrow. The variability measures corresponds very well with the graphical representation of the distribution.  

#### Age  
The mean and trimmed mean is actually really close to each other but when the value is rounded off the difference increases but the two values (12 and 13) is still close to each other. From this I can deduce that there is not many data points in the outer 10 % of the lower and upper part of the distribution. The mean and median is also very close to each other so the balance of the distribution is in the center of the distribution. The mode value is equal to the trimmed mean and median which indicates a normal distribution which can be confirmed by the visual representation of the histogram and density curve. Since the mean value is smaller than the median value a small negative skew can be seen. The central tendency values and the visual representation corresponds very well with each other. The youngest person in the population is 3 years old and the oldest is 19 years old. The IQR value of 6 indicates that the central 50 % of the data is spread out among those 6 years. The SD value of 4 indicate how far from the mean value that the data is spread out. The value indicates that there is some spread among the observations for this variable but nothing of big concern. The variability measures correspons very well with the visual representation of the distribution.  

#### Height in meter  
The mean and trimmed mean is almost identical so no crucial data points is located in the outer 10 % of the scale for this variable. The same goes for the mode value which is identical with the medial value. This indicates a symmetric distribution and when looking at the visual representation of the distribution this corresponds very well with the values. The shortest person in the observations is 1.15062 meter and the tallest person is 2.07772 meter. The IQR value of 0.26416 indicates that the central 50 % of the data is not that wide spread out. The SD value (0.1829345) is relatively small and indicates that the data for this variable is not that wide spread out. The variability measures corresponds very well with the graphical representation of the distribution.  

I have chosen to leave out some of the variables when it did not add any value to the project to analyze variables such as true-false variables and other categorical variables.  

I general the graphical representation gives the same impression as the values of central tendency measures and variability measures. However it can be difficult to read the exact values from the graphical representation and the central tendency measures and variability measures helps to understand the exact values.  
When the values are rounded some details becomes hidden from the central tendency measures. The data representation can either be in numeric form or visual form depending on how you want to present the data and with what purpose. Usually it is easier to get an overview from the visual representation but the details is easier seen in the numerical representation of the data.  

# Stage 3

## Linear relationships between variables  

### Numerical variables  
In the following I will look at the linear regression between different variables. To be able to look at the linear relationship between variables I will first look at the correlation coefficient, first in a correlation matrix and then I will visualize it with a heat map. A heat map relates the numeric value from -1 to 1 into a color code where red represents a value of 1 and blue represents a value of -1. 0 indicates a non-correlation. To make the heat map a bit easier to read I have rounded the numerical value to two decimal numbers.  

First the variables has to be selected. I have selected: DOM




# Lottery - Stage 4

## Viking Lotto  
I have chosen one of the Danish lottery systems, known as "Viking Lotto", which can be found here:
https://danskespil.dk/vikinglotto/vindertal  

The lottery ticket has a game board with 36 elements which are the numbers from 1-36. The player should choose 7 numbers on the game board - this is known as a row.  

Once a week the lottery numbers are drawn. There is drawn 7 winning numbers and 2 additional numbers.  
The criteria for a success is:  
- 6 winning numbers plus 1 of the additional numbers.  
- 6 winning numbers.  
- 5 winning numbers plus 1 of the additional numbers.  
- 5 winning numbers.  
- 4 winning numbers plus 1 of the additional numbers.  
- 4 winning numbers.  
- 3 winning numbers.  

In the lottery the sequence of the 7 winning numbers is selected among the fist 36 positive integers and the sequence of the winning numbers is not relevant. To calculate the possible sequences of winning numbers I use the formula:  
(n,k) = n(n-1)...(n-k+1) / k(k-1)...1  
The same formula can be written with factorials:  
n! / (k!*(n-k)!), when k <= n, and which is zero when k>n.
```{r}
kombin <- function(n,k)
{
  factorial(n) / (factorial(k)*factorial(n-k))
}
```
The number of possible rows is (36,7) = 8347680.
```{r}
kombin(36,7)
```
I will start out with the simplest of the cases where I only focus on the winning numbers.  
Let x denote the number of correct winning numbers.  
The number of rows with x number of correct winning numbers is (7,x)*(29,7-x), which is the number of ways the correct x numbers can be among the correct 7 winning numbers multiplied with the number of ways the remaining 7-x numbers in the row can be selected from the 29 numbers which are not the correct winning numbers.  
P(x) = ((7,x)*(29,7-x)) / (36,7)  
**x = 6  **
```{r}
(kombin(7,6)*kombin(29,7-6)) / kombin(36,7)
```
**x = 5**
```{r}
(kombin(7,5)*kombin(29,7-5)) / kombin(36,7)
```
**x = 4**
```{r}
(kombin(7,4)*kombin(29,7-4)) / kombin(36,7)
```
**x = 3**
```{r}
(kombin(7,3)*kombin(29,7-3)) / kombin(36,7)
```
The above results only focus on the cases where the winning numbers are drawn and not the additional numbers. The additional numbers is two numbers. Let y denote the number of correct additional numbers. I can either have 0, 1 or 2 correct additional numbers.  
I will use the following formula:  
P(x correct winning numbers and y correct additional numbers) = ( (7,x)* (2,y)* (27,7-(x+y)) ) / (36,7)  

First I'll find the number of combinations for x to be among the correct 7 winning numbers, they are multiplied with the number of combinations for y to be among the correct 2 additional numbers, multiplied with the number of ways where the remaining 7-(x and y) numbers of the row is selected among the 27 numbers which is not correct.

If I have **6 winning numbers and 1 additional number** the formula looks like this:  
P(6,1) = ( (7,6)* (2,1)* (27,7-(6+1)) ) / (36,7)
```{r}
(kombin(7,6)*kombin(2,1)*kombin(27,7-(6+1))) / kombin(36,7)
```
**5 winning numbers and 1 additional number**
```{r}
(kombin(7,5)*kombin(2,1)*kombin(27,7-(5+1))) / kombin(36,7)
```
**4 winning numbers and 1 additional number**
```{r}
(kombin(7,4)*kombin(2,1)*kombin(27,7-(4+1))) / kombin(36,7)
```
It would make sense that the lower the probability the higher the price. The order of the price is related to the number of correct winning numbers and additional numbers: 6 winning numbers + 1 additional number > 6 winning numbers > 5 winning numbers + 1 additional number > 5 winning numbers  > 4 winning numbers + 1 additional number > 4 winning numbers > 3 winning numbers.  
Let's compare the probability the highest price should have the lowest probability
```{r}
"(kombin(7,6)*kombin(2,1)*kombin(27,7-(6+1))) / kombin(36,7)"<"(kombin(7,6)*kombin(29,7-6)) / kombin(36,7)<(kombin(7,5)*kombin(2,1)*kombin(27,7-(5+1))) / kombin(36,7)<(kombin(7,5)*kombin(29,7-5)) / kombin(36,7)<(kombin(7,4)*kombin(2,1)*kombin(27,7-(4+1))) / kombin(36,7)<(kombin(7,4)*kombin(29,7-4)) / kombin(36,7)<(kombin(7,3)*kombin(29,7-3)) / kombin(36,7)"
```
```{r}
(kombin(7,6)*kombin(2,1)*kombin(27,7-(6+1))) / kombin(36,7)
(kombin(7,6)*kombin(29,7-6)) / kombin(36,7)
(kombin(7,5)*kombin(2,1)*kombin(27,7-(5+1))) / kombin(36,7) 
(kombin(7,5)*kombin(29,7-5)) / kombin(36,7)
(kombin(7,4)*kombin(2,1)*kombin(27,7-(4+1))) / kombin(36,7)
(kombin(7,4)*kombin(29,7-4)) / kombin(36,7)
(kombin(7,3)*kombin(29,7-3)) / kombin(36,7)
```
I have both evaluated that the highest price is associated with the lowest probability and when the probability increases the price is decreasing. It can be observed that there is a lower probability of getting x number of winning numbers and the additional numbers, than just the winning numbers. This makes quite good sense the probability of the correct additional numbers is multiplied in the equation. If we look at the result numbers we have to remember that it is a value between 0-1, where 0 indicates no probability of the outcome (it is impossible) and 1 indicates it will happen for sure. There is a very small chance to win in the lottery, even just to have 3 correct winning numbers.